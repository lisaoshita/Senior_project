---
title: "Caret Package"
author: "Lisa Oshita"
date: "12/19/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Caret package functionality 

* preprocessing - data cleaning
* data splitting: createDataPartition, createResample, createTimeSlices
* training/testing functions: train, predict
* model comparison: confusionMatrix

```{r, echo = FALSE}
# loading packages + data
library(caret); library(kernlab)
data(spam)
```

### Data splitting

```{r}
# p = percentage of data that goes to training
# list = whether or not results returned as list or matrix 
# gives all observations that will be in training data 
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE) 
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
dim(training) 
```

### Model fitting

```{r}
set.seed(32343)

# ~. tells the model to use all other variables in df 
modelFit <- train(type~., data = training, method = "glm")
modelFit
modelFit$finalModel # to view coefficients of model 

predictions <- predict(modelFit, newdata = testing)
predictions

# confusion matrix to determine how well the model predicts
confusionMatrix(predictions, testing$type)
```

### Data slicing

```{r}
# createDataPartition as above
# k-fold (from caret package)
set.seed(32323)
folds <- createFolds(y = spam$type, k = 10, list = TRUE, returnTrain = TRUE) # if returnTrain false, will return test sets
sapply(folds, length)

# resampling/bootstrapping: createResample()
set.seed(32323)
folds1 <- createResample(y = spam$type, times = 10, list = TRUE)
sapply(folds1, length)
```

##### Metric options

* continuous
    + RMSE = root mean squared error (default)
    + Rsquared 
* categorical
    + Accuracy = fraction correct (default)
    + Kappa = measure of concordance
    
### Plotting predictors

```{r}
library(ISLR); library(ggplot2)
data(Wage)
summary(Wage) # shows that all in Mid-Atlantic region

inTrain <- createDataPartition(y = Wage$wage, p = 0.7, list = FALSE)
training_w <- Wage[inTrain, ]
testing_w <- Wage[-inTrain, ]
dim(training); dim(testing)

# examine age, education, job class with wage as outcome
caret::featurePlot(x = training_w[, c("age", "education", "jobclass")], 
            y = training_w$wage,
            plot = "pairs")

qq <- ggplot2::qplot(age, wage, colour = education, data = training_w)
# adding regression smoothers
qq + geom_smooth(method = "lm", formula = y ~ x)
```

##### Making factors

```{r}
# g = how many groups to break into 
cutWage <- Hmisc::cut2(training_w$wage, g = 3)
table(cutWage)

# use to make plots
p1 <- qplot(cutWage, age, data = training_w, fill = cutWage, geom = c("boxplot"))
p1

# use to make tables

t1 <- table(cutWage, training_w$jobclass)
t1
prop.table(t1, 1) # 1 = proportion for each row, 2 = proportion for each column
```

#### Basic preprocessing

##### Centering + scaling

```{r}
hist(training$capitalAve, main = "", xlab = "ave. capital run length") # indicates right skewed, use pre-processing

# standardize variables on training set
trainCapAve <- training$capitalAve
trainCapAveS <- (trainCapAve - mean(trainCapAve)) / sd(trainCapAve)
mean(trainCapAveS); sd(trainCapAveS)

# standardize variables on test set
# NOTE: when applying this standardization to the test set, must use the mean and sd from the training set 
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve - mean(trainCapAve)) / sd(trainCapAve)
mean(testCapAveS); sd(testCapAveS)

# using preprocess function
preObj <- caret::preProcess(training[,-58], method = c("center", "scale"))
trainCapAveS1 <- predict(preObj, training[,-58])$capitalAve
mean(trainCapAveS1); sd(trainCapAveS1)

testCapAveS1 <- predict(preObj, testing[,-58])$capitalAve
mean(testCapAveS1); sd(testCapAveS1)

# used in a model function
set.seed(32343)
modelFit1 <- train(type ~., data = training, preProcess = c("center", "scale"), method = "glm")
modelFit1
```

##### Other transformations

```{r}
# Box Cox transformations 
preObj1 <- preProcess(training[,-58], method = c("BoxCox"))
trainCapAveS2 <- predict(preObj1, training[,-58])$capitalAve
hist(trainCapAveS2); qqnorm(trainCapAveS2)
```

##### Imputing data

```{r}
set.seed(13343)
# Make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1], size = 1, prob = 0.05) == 1
training$capAve[selectNA] <- NA

# impute and standardize 
library(RANN)
preObj2 <- preProcess(training[,-58], method = "knnImpute") # k nearest neighbors imputation 
capAve <- predict(preObj2, training[,-58])$capAve

# standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth - mean(capAveTruth)) / sd(capAveTruth)

quantile(capAve - capAveTruth)
quantile((capAve - capAveTruth)[selectNA]) # looking at just imputed values
```

#### Covariate creation

* Level 1: from raw data to covariate
    + Text files: frequency of words/phrases/capital letters
    + Images: corners, blobs...
    + Webpages: number/type of images, A/B testing
    + When in doubt, err on the side of more features
* Level 2: transforming tidy covariates 
    + More necessary for some methods (regression, svms) than others (classification trees)
    + Should be done only on the training set

```{r}
# working with Wage data

# dummy variables (hard for algorithms to work with qualitative variables)
dummies <- caret::dummyVars(wage ~ jobclass, data = training_w)
head(predict(dummies, newdata = training_w))

# removing zero covariates
nsv <- nearZeroVar(training_w, saveMetrics = TRUE)
nsv # may want to remove region, doesn't have any variability, should not be used in prediction algorithms

# spline basis
library(splines)
bsBasis <- bs(training_w$age, df = 3) # 3rd degree polynomial
bsBasis # first column = age, second = age^2, third = age^3

# fitting curves with splines
lm1 <- lm(wage ~ bsBasis, data = training_w)
plot(training_w$age, training_w$wage, pch = 19, cex = 0.5)
points(training_w$age, predict(lm1, newdata = training), col = "red", pch = 19, cex = 0.5)

# splines on test set
predict(bsBasis, age = testing_w$age)
```

#### Preprocessing with PCA

* basic idea of PCA
    + might not need every predictor - weighted combinations of predictors may be better
    + benefits: reduced number of predictors, reduced noise (due to averaging), while maintaining accuracy 
* ex: multivariate variables x1,...,xn so x1 = (x11, x12,..., x1n)
    + find a new set of multivariate variables that are uncorrelated and explain as much variance as possible 
    + if put all variables together in one matrix, find best matrix created with fewer variables (lower rank) that explains the data
    + first goal is statistical, second is data compression
* related solutions to above: PCA/SVD
    + SVD: matrix decomposition
    + PCA
* useful for linear models
    
```{r}
# correlated predictors 
# working with spam data
M <- abs(cor(training[,-58])) # finding absolute value of the correlations of predictors
diag(M) <- 0 # zeroing out diagonals, since every predictor is correlated with itself
which(M > 0.8, arr.ind = TRUE) # which variables are correlated 

plot(spam$num415, spam$num857)

# find a combination of correlated variables that best explains the variability in the data 
x <- (0.71 * training$num415) + (0.71 * training$num857)
y <- (0.71 * training$num415) - (0.71 * training$num857)

plot(x, y) # indicates that adding the two variables together (x) captures most of the variability

# PCA function 
smallSpam <- spam[,c(32,34)]
prComp <- prcomp(smallSpam)
plot(prComp$x[,1], prComp$x[,2])
prComp$rotation # rotation matrix

# PCA with spam
typeColor <- ((spam$type == "spam") * 1 + 1)
prComp1 <- prcomp(log10(spam[,-58] + 1))
plot(prComp1$x[,1], prComp1$x[,2], col = typeColor, xlab = "PC1", ylab = "PC2") # indicates that along principal component 1 space, there is more separation between the ham and spam 

# PCA with caret package
preProc <- preProcess(log10(spam[,-58] + 1), method = "pca", pcaComp = 2)
spamPC <- predict(preProc, log10(spam[, -58] + 1))
plot(spamPC[,1], spamPC[,2], col = typeColor)
```

#### Predicting with Regression

```{r}
# using faithful data 
data("faithful")
set.seed(333)
inTrain1 <- createDataPartition(y = faithful$waiting, p = 0.5, list = FALSE)
trainFaith <- faithful[inTrain1,]
testFaith <- faithful[-inTrain1,]
head(trainFaith)
```

```{r}
# fit model
lm1 <- lm(eruptions ~ waiting, data = trainFaith)
summary(lm1)
plot(trainFaith$waiting, trainFaith$eruptions, pch = 19, col = "blue", xlab = "Waiting", ylab = "Duration")
lines(trainFaith$waiting, lm1$fitted, lwd = 3)

# predictions
coef(lm1)[1] + (coef(lm1)[2] * 80)
newdata <- data.frame(waiting = 80)
predict(lm1, newdata)

# plot predictions
plot(testFaith$waiting, testFaith$eruptions, pch = 19, col = "blue", xlab = "Waiting", ylab = "Duration")
lines(testFaith$waiting, predict(lm1, newdata = testFaith), lwd = 3)

# get training/test set errors
# RMSE on training
sqrt(sum((lm1$fitted - trainFaith$eruptions)**2))
# RMSE on test
sqrt(sum((predict(lm1, newdata = testFaith) - testFaith$eruptions)**2))

# prediction intervals
pred1 <- predict(lm1, newdata = testFaith, interval = "prediction")
ord <- order(testFaith$waiting)
plot(testFaith$waiting, testFaith$eruptions, pch = 19, col = "blue")
matlines(testFaith$waiting[ord], pred1[ord, ], type = "l",, col = c(1,2,2), lty = c(1,1,1), lwd = 3)

# with caret package
modFit <- train(eruptions ~ waiting, data = trainFaith, method = "lm")
summary(modFit$finalModel)
```




